{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer Sales, Preferences, and the Macroeconomy\n",
    "### Data Engineering Platforms (Fall 2019) | The University of Chicago\n",
    "\n",
    "## 0. Introduction\n",
    "\n",
    "### 0.1. Executive summary \n",
    "\n",
    "Alcohol is one of the most popular purchases in the US, but does consumersâ€™ love of beer vary with their economic condition? In this project, we seek to derive insights on alcohol consumption patterns with respect to changes in US economic metrics. \n",
    "\n",
    "Questions that this project can potentially answer:\n",
    "\n",
    "- Do preferences for beer types change during recession? Do consumers favor particular beers, price points, or alcohol content?\n",
    "- How does unemployment affect beer purchasing? Does it significantly impact the total amount purchased, or just shifts the product mix?\n",
    "\n",
    "### 0.2. Business use case\n",
    "\n",
    "This project can provide insight into consumer purchasing habits, which is highly desirable to a variety of businesses. Breweries can use this data to plan their production, such that they focus their production on the beer with the highest expected demand. Retailers and restaurants can use this data to plan their inventory, stocking particular products ahead of expected increases in demand.\n",
    "\n",
    "### 0.3. Methodology\n",
    "\n",
    "The order of operation is as follows: \n",
    "\n",
    "1. First, the schema (snowflake EER) of the final MySQL database is designed upon examining the data.  \n",
    "2. The relevant data from the IRI dataset are combined in groups and read into dataframes in Python. \n",
    "3. Text columns that appear to be non-categorical are clustered in OpenRefine. \n",
    "4. The clustered results then are used as a dictionary to normalise said dataframes. \n",
    "5. The dataframes are then read into a local MySWL server in observance of foreign key constraints, and upon verification, is migrated to Google Cloud SQL. \n",
    "6. This then allows data access for visualisation (and statistical analysis in the future) by various stakeholders using Python, R, and Tableau. \n",
    "\n",
    "### 0.4. Data sources\n",
    "\n",
    "- The IRI Academic Marketing Data Set (Bronnenberg, et al, 2012) - 130 GB unzipped - NDA required, access through The University of Chicago Office of Research and National Laboratories Research Computing Center \n",
    "- St. Louis Fed Federal Research Economic Data (FRED) - through FRED API\n",
    "\n",
    "### 0.5 Prerequisites\n",
    "\n",
    "System requirements: 50 GB of free drive space. 8 GB memory. Jupyter Lab/Notebook, OpenRefine 3.2, MySQL 8.0.18 server, MySQL Workbench 8.0, Google Cloud Platform, Cloud SQL, and Tableau.\n",
    "\n",
    "The MySQL database size will be approximately **17 GB**. Check by running the following code in MySQL:  \n",
    "\n",
    "SELECT table_schema 'database name',  \n",
    "  sum( data_length + index_length ) / 1024 / 1024 /1024 'data Base Size in GB'  \n",
    "FROM information_schema.TABLES  \n",
    "GROUP BY table_schema;\n",
    "\n",
    "MySQL Workbench DBMS connection read timeout interval to be set at >3600 seconds.\n",
    "\n",
    "Section 4 requires an empty schema `beer` in MySQL 8. The code is provided in `section 4.0`. \n",
    "\n",
    "The following packages are also required and can be installed using `pip` or `conda`:  \n",
    "`os`, `glob` (allows for UNIX-style pathname pattern expansion), `NumPy`, `pandas 0.25` , `sqlalchemy` (writes records stored in a DataFrame to a SQL database), `tqdm` (low overhead iterable progress bar), and `fredapi` (pulls data from St Louis Fed FRED API).\n",
    "\n",
    "**IMPORTANT**: pandas version `0.24.+` is required as pandas has gained the ability to hold integer dtypes with missing values.\n",
    "\n",
    "### 0.6. Sections in this notebook\n",
    "\n",
    "The following sections in this notebook progress as follows: \n",
    "\n",
    "Section 1 explains the procedure to access the IRI dataset on UChicago Research Computing Center and documents the steps taken to extract the necessary files and directories pertinent to this project, given the limitations of the memory size of personal laptop computers. \n",
    "\n",
    "Section 2 provides an overview of the IRI dataset and its various dimensions, their limitations. \n",
    "\n",
    "Section 3 describes the fact-dimension schema in MySQL. \n",
    "\n",
    "Section 4 includes the code to create an blank schema on a local MySQL server.\n",
    "\n",
    "Section 5-9 works with import, transformation, normalisation, and pushing data (product, store, sales, dates, and economic data) onto the local MySQL server. \n",
    "\n",
    "Section 10 details the steps taken to migrate the database from local server to Google Cloud SQL. \n",
    "\n",
    "Section 11 gives a quick run-down of Cloud SQL access for data visualisation and analysis in Tableau.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IRI Data extraction:\n",
    "\n",
    "0. Sign NDA for the IRI Academic Database. \n",
    "\n",
    "1. Connect to RCC /project2: <https://rcc.uchicago.edu/docs/data-transfer/index.html> smb://midwaysmb.rcc.uchicago.edu/project2 Username: ADLOCAL\\CNetID Password: CNet password Hostname: midwaysmb.rcc.uchicago.edu\n",
    "\n",
    "2. Navigate to `/project2/databases/IRIData/`\n",
    "\n",
    "3. Unzip `zYearXX` files and extract beer directory\n",
    "\n",
    "4. Relocate contents of `BEER` directory into `YearXX` directory\n",
    "\n",
    "5. Rename `zparsed stub files.zip` as `parsed stub files.zip`\n",
    "\n",
    "6. Collect all BEER product attribute files `parsed stub files` into the directory \"beer_attributes\".\n",
    "\n",
    "  - Renamed `prod_beer.xlsx` and `prod_beer_sz.xlsx` from the `parsed stub files` directory as `prod01_beer.xlsx` and `prod01_beer_sz.xlsx`.\n",
    "  - Renamed prod_beer.xlsx from the `parsed stub files 2007` directory as `prod07_beer.xlsx`.\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Overview of the `IRI dataset`:\n",
    "\n",
    "Dataset size: 8 GB unzipped\n",
    "\n",
    "Dataset range: January 1, 2001 (week 1114) to December 30, 2012 (1739).\n",
    "\n",
    "Data sets are separated by year. In each year, there are the following files:\n",
    "\n",
    "- `ADB Measure Definitions.doc` defines store measures\n",
    "- `Delivery_Stores` defines stores included in the year's files\n",
    "- `demos.csv` identifies the demographics of the panelists\n",
    "- `IRI week translation.xls` defines the conversion of week numbers to dates.\n",
    "- `panel_measure_definition.doc` defines panel measures. This file is slightly different for years 2008-2011.\n",
    "- `Category_outlet_startweek_endweek` with no file extension contains store-week level data\n",
    "- `Category_PANEL_outlet_startweek_endweek.dat` DAT file contains panel data at transaction level.\n",
    "\n",
    "**TO DO** For years 1, 2, 6, 7, and 12, the `DEMOS.csv` files are located in the directory `demo trips external`. Move these into each YearXX directory.\n",
    "\n",
    "Note that for 2001-2007, the outlet categories are:\n",
    "- {DR: drug, GR: groceries, MA: mass}. \n",
    "\n",
    "For 2008-2011, the outlet categories are:\n",
    "- {DK: drug, GK: groceries, MK: mass}.\n",
    "\n",
    "### 2.1. Week numbers - `IRI WEEK Translation` file description:\n",
    "\n",
    "- End date = (weekNumber - 400) * 7 + 31900\n",
    "- Start date = (weekNumber - 400) * 7 + 31900 - 6\n",
    "\n",
    "### 2.2. Sales data - `Category_outlet_startweek_endweek` file description:\n",
    "\n",
    "The store data files are the largest files.\n",
    "\n",
    "Both the store data and panel data files are keyed to the dimensional information (store, week, UPC fields, [panelist]).\n",
    "\n",
    "Records within a file represent a transaction by store-week-upc (universal product code).\n",
    "\n",
    "**Naming convention:** The naming convention for these is category name then outlet then start week and then end week, all separated by underscores, with no extension, so salted snacks drug data for the earliest year would be `saltsnck_drug_1114_1165`.\n",
    "\n",
    "**Columns of interest:**\n",
    "\n",
    "- IRI_Key FK: Delivery_Stores\n",
    "- WEEK FK: IRI Week Translation.xls\n",
    "- SY FK: UPC system code\n",
    "- GW FK: UPC generation code\n",
    "- VEND FK: UPC vendor code\n",
    "- ITEM FK: UPC item code\n",
    "- UNITS Units sold\n",
    "- DOLLARS Amount (note below)\n",
    "\n",
    "The dollars column reflects the retail price paid, on average, after retail features, displays and retail coupons. It does not include manufacturer coupons or any discount that might be applied by the retailer that is not applicable to the item. For example, if a retailer gave USD5 off if you purchased more than USD200, that discount is not applied. Sales taxes are not included.\n",
    "\n",
    "The F column denotes whether there was a marketing feature within the store, such a small or large-sized ad. The D column denotes whether there was a marketing display of the product within the store.\n",
    "\n",
    "### 2.3. `Delivery_Stores` file description:\n",
    "\n",
    "The file contains each store \"masked\" using the sequence key as it's identifier across the various tables. This file also contains outlet, estimated acv, the market name so data can be aggregated by market, an open and close week, and finally a \"chain\" number representing a particular retailer. All the stores belonging to Chain8 are part of the same retailer that year.\n",
    "\n",
    "**Columns of interest:**\n",
    "\n",
    "- IRI_KEY: FK: masked store ID, **maybe different from year to year**. Cross-reference in Appendix 2 of the data dictionary. <- ignore this for now\n",
    "- OU: drug/groceries/mass market -> into its own NF table EST_ACV: estimate of annualized sale in MILLIONS for the store across ALL categories\n",
    "- Market_Name: 50 markets total -> into its own NF table\n",
    "\n",
    "### 2.4. Product attributes (in directory \"beer_attributes\"):\n",
    "\n",
    "`prod01_beer.xlsx` and prod01_beer_sz.xlsx for 2001-2006.<br>\n",
    "`prod07_beer.xlsx` for 2007.<br>\n",
    "`prod11_beer.xlsx` for 2008-2011.<br>\n",
    "`prod12_beer` for 2012.\n",
    "\n",
    "`prod01_beer_sz.xlsx` describes additional size attribute information. No size information was provided for 2007 onward.\n",
    "\n",
    "**Columns of interest:**\n",
    "\n",
    "- L2 Small category (domestic or import) -> into its own NF table\n",
    "- L4 Vendor -> into its own NF table\n",
    "- L5 Brand -> into its own NF table\n",
    "- SY UPC system code\n",
    "- GW UPC generation code\n",
    "- VEND UPC vendor code\n",
    "- ITEM UPC item code -> for each UPC item, generate a surrogate key\n",
    "- VOL_EQ Volume equivalent := ounces / 192\\. Denotes total beer per unit sold (e.g. total volume in bottle/can/4-pack/6-pack/case/keg) **TO DO:** figure out a way to determine volume of each individual package\n",
    "- TYPE OF BEER/ALE **Admit PRODUCT TYPE if MISSING** -> into its own NF table\n",
    "- PACKAGE Packaging (can/glass, single, box, carton, keg, etc...) -> into its own NF table\n",
    "- FLAVOR/SCENT FLAVOR[FLAVOR = MISSING] <- NULL, -> into its own NF table\n",
    "\n",
    "Note: Columns CALORIE LEVEL and COLOR have too many missing values to be useful for analysis.\n",
    "\n",
    "### ~~2.5. Category_PANEL_outlet_startweek_endweek.dat~~:\n",
    "\n",
    "Panel data is provided for two \"BehaviorScan\" markets, Eau Claire, Wisconsin and Pittsfield, Massachusetts.\n",
    "\n",
    "Outside the scope of this project.\n",
    "\n",
    "### ~~2.6. Panel trips~~:\n",
    "\n",
    "These files represent the trips made by panelists who purchased at least one item.\n",
    "\n",
    "Outside the scope of this project.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. MySQL DDL\n",
    "\n",
    "<img src= \"beer_eer_diagram.png\" width=\"700\" />\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create schema in MySQL server\n",
    "\n",
    "In MySQL Workbench, create the schema/EER the `beer` database on a local MySQL server using the DDL script `beer_ddl.sql`.\n",
    "\n",
    "Note: When populating the database with data, it is **paramount** that the data for the tips of the snowflake is inputted first, and the fact tables (`sales`) and `econ` be inserted last. Otherwise, it would throw a `FOREIGN_KEY_CHECKS` error (ERROR 1452: Cannot add or update a child row: a foreign key constraint fails).\n",
    "\n",
    "Note note: For each instance a MySQL table is populated, there will be a binary log generated. Since the SALES data is large, the corresponding binary log will also be large, taking up space in your storage up to 5GB at a time. To purge the binary logs, use the script `PURGE BINARY LOGS BEFORE '<DATETIME>';`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Product data\n",
    "\n",
    "### 5.1 Extraction of columns for clustering in OpenRefine\n",
    "\n",
    "There are three columns from the `UPC` product table that require text clustering, namely, `flavor`, `packaging`, and `beer-type`.\n",
    "\n",
    "The unique values in each of these three columns are extracted into three separate dataframes. In each dataframe, the column is duplicated with the following naming convention to preserve changes for future validation: `xxx_name` represent original names, `xxx_cat` represent categories post-clustering. These dataframes are stored as `.csv` files in the directory `\"./OpenRefine_data/pre-openrefine/`. Files that have been clustered using OpenRefine are located in the directory `\"./OpenRefine_data/pre-openrefine/` and have `-or` appended to their filenames. \n",
    "\n",
    "We first import the packages and settings required for the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from fredapi import Fred\n",
    "\n",
    "# MySQL server credentials\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\".format(user=\"root\", pw=\"rootroot\", db=\"beer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the product tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the product tables combined is (56938, 23)\n"
     ]
    }
   ],
   "source": [
    "prod_all_beer_df = pd.concat([pd.read_excel(f) for f in glob.glob(\"./IRI BEER DATASET/beer_attributes/prod*_beer.xls*\")], ignore_index = True, sort=False)\n",
    "print(\"The dimensions of the product tables combined is\", prod_all_beer_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>L5</th>\n",
       "      <th>L9</th>\n",
       "      <th>Level</th>\n",
       "      <th>UPC</th>\n",
       "      <th>SY</th>\n",
       "      <th>GE</th>\n",
       "      <th>...</th>\n",
       "      <th>VOL_EQ</th>\n",
       "      <th>PRODUCT TYPE</th>\n",
       "      <th>TYPE OF BEER/ALE</th>\n",
       "      <th>PACKAGE</th>\n",
       "      <th>FLAVOR/SCENT</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>CALORIE LEVEL</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>*AG C=1+ CATEGORY                                                        00004</th>\n",
       "      <th>*STUBSPEC 1416RC                                                         00004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CATEGORY - BEER/ALE/ALCOHOLIC CID</td>\n",
       "      <td>DOMESTIC BEER/ALE (INC NON-ALCOH</td>\n",
       "      <td>ABC WINE &amp; SPIRITS</td>\n",
       "      <td>ABC WINE &amp; SPIRITS</td>\n",
       "      <td>ABC ALE</td>\n",
       "      <td>+ABCAL ALE BEER CAN 12OZ</td>\n",
       "      <td>9</td>\n",
       "      <td>00-01-85674-60002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>BEER</td>\n",
       "      <td>ALE</td>\n",
       "      <td>CAN</td>\n",
       "      <td>NO FLAVOR</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CATEGORY - BEER/ALE/ALCOHOLIC CID</td>\n",
       "      <td>DOMESTIC BEER/ALE (INC NON-ALCOH</td>\n",
       "      <td>ABC WINE &amp; SPIRITS</td>\n",
       "      <td>ABC WINE &amp; SPIRITS</td>\n",
       "      <td>ABC ALE</td>\n",
       "      <td>+ABCAL ALE BEER CAN 72OZ</td>\n",
       "      <td>9</td>\n",
       "      <td>00-01-85674-60001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>BEER</td>\n",
       "      <td>ALE</td>\n",
       "      <td>CAN</td>\n",
       "      <td>NO FLAVOR</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CATEGORY - BEER/ALE/ALCOHOLIC CID</td>\n",
       "      <td>DOMESTIC BEER/ALE (INC NON-ALCOH</td>\n",
       "      <td>ABITA BREWING CO INC</td>\n",
       "      <td>ABITA BREWING CO INC</td>\n",
       "      <td>ABITA AMBER</td>\n",
       "      <td>+ABTAM LAGER BEER GB 12OZ</td>\n",
       "      <td>9</td>\n",
       "      <td>27-01-15502-01124</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>BEER</td>\n",
       "      <td>LAGER</td>\n",
       "      <td>GLASS BOTTLE</td>\n",
       "      <td>NO FLAVOR</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>AMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CATEGORY - BEER/ALE/ALCOHOLIC CID</td>\n",
       "      <td>DOMESTIC BEER/ALE (INC NON-ALCOH</td>\n",
       "      <td>ABITA BREWING CO INC</td>\n",
       "      <td>ABITA BREWING CO INC</td>\n",
       "      <td>ABITA AMBER</td>\n",
       "      <td>+ABTAM LAGER BEER GB 12OZ</td>\n",
       "      <td>9</td>\n",
       "      <td>00-01-80020-00001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>BEER</td>\n",
       "      <td>LAGER</td>\n",
       "      <td>GLASS BOTTLE</td>\n",
       "      <td>NO FLAVOR</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>AMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CATEGORY - BEER/ALE/ALCOHOLIC CID</td>\n",
       "      <td>DOMESTIC BEER/ALE (INC NON-ALCOH</td>\n",
       "      <td>ABITA BREWING CO INC</td>\n",
       "      <td>ABITA BREWING CO INC</td>\n",
       "      <td>ABITA AMBER</td>\n",
       "      <td>+ABTAM LAGER BEER GBCRT 72OZ</td>\n",
       "      <td>9</td>\n",
       "      <td>00-01-80020-24221</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>BEER</td>\n",
       "      <td>LAGER</td>\n",
       "      <td>GLASS BOTTLE IN CRTN</td>\n",
       "      <td>NO FLAVOR</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>AMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  L1                                L2  \\\n",
       "0  CATEGORY - BEER/ALE/ALCOHOLIC CID  DOMESTIC BEER/ALE (INC NON-ALCOH   \n",
       "1  CATEGORY - BEER/ALE/ALCOHOLIC CID  DOMESTIC BEER/ALE (INC NON-ALCOH   \n",
       "2  CATEGORY - BEER/ALE/ALCOHOLIC CID  DOMESTIC BEER/ALE (INC NON-ALCOH   \n",
       "3  CATEGORY - BEER/ALE/ALCOHOLIC CID  DOMESTIC BEER/ALE (INC NON-ALCOH   \n",
       "4  CATEGORY - BEER/ALE/ALCOHOLIC CID  DOMESTIC BEER/ALE (INC NON-ALCOH   \n",
       "\n",
       "                     L3                    L4           L5  \\\n",
       "0    ABC WINE & SPIRITS    ABC WINE & SPIRITS      ABC ALE   \n",
       "1    ABC WINE & SPIRITS    ABC WINE & SPIRITS      ABC ALE   \n",
       "2  ABITA BREWING CO INC  ABITA BREWING CO INC  ABITA AMBER   \n",
       "3  ABITA BREWING CO INC  ABITA BREWING CO INC  ABITA AMBER   \n",
       "4  ABITA BREWING CO INC  ABITA BREWING CO INC  ABITA AMBER   \n",
       "\n",
       "                             L9  Level                UPC  SY  GE  ...  \\\n",
       "0      +ABCAL ALE BEER CAN 12OZ      9  00-01-85674-60002   0   1  ...   \n",
       "1      +ABCAL ALE BEER CAN 72OZ      9  00-01-85674-60001   0   1  ...   \n",
       "2     +ABTAM LAGER BEER GB 12OZ      9  27-01-15502-01124  27   1  ...   \n",
       "3     +ABTAM LAGER BEER GB 12OZ      9  00-01-80020-00001   0   1  ...   \n",
       "4  +ABTAM LAGER BEER GBCRT 72OZ      9  00-01-80020-24221   0   1  ...   \n",
       "\n",
       "   VOL_EQ  PRODUCT TYPE TYPE OF BEER/ALE               PACKAGE FLAVOR/SCENT  \\\n",
       "0  0.0417          BEER              ALE                   CAN    NO FLAVOR   \n",
       "1  0.2500          BEER              ALE                   CAN    NO FLAVOR   \n",
       "2  0.0417          BEER            LAGER          GLASS BOTTLE    NO FLAVOR   \n",
       "3  0.0417          BEER            LAGER          GLASS BOTTLE    NO FLAVOR   \n",
       "4  0.2500          BEER            LAGER  GLASS BOTTLE IN CRTN    NO FLAVOR   \n",
       "\n",
       "      SIZE CALORIE LEVEL    COLOR  \\\n",
       "0  MISSING       MISSING  MISSING   \n",
       "1  MISSING       MISSING  MISSING   \n",
       "2  MISSING       MISSING    AMBER   \n",
       "3  MISSING       MISSING    AMBER   \n",
       "4  MISSING       MISSING    AMBER   \n",
       "\n",
       "  *AG C=1+ CATEGORY                                                        00004    \\\n",
       "0                                                NaN                                 \n",
       "1                                                NaN                                 \n",
       "2                                                NaN                                 \n",
       "3                                                NaN                                 \n",
       "4                                                NaN                                 \n",
       "\n",
       "  *STUBSPEC 1416RC                                                         00004    \n",
       "0                                                NaN                                \n",
       "1                                                NaN                                \n",
       "2                                                NaN                                \n",
       "3                                                NaN                                \n",
       "4                                                NaN                                \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_all_beer_df[\"FLAVOR/SCENT\"] = prod_all_beer_df[\"FLAVOR/SCENT\"].replace(\"MISSING\", \"NO FLAVOR\").replace(\"REGULAR\", \"NO FLAVOR\")\n",
    "prod_all_beer_df[\"PACKAGE\"] = prod_all_beer_df[\"PACKAGE\"].replace(\"MISSING\", \"UNKNOWN\")\n",
    "prod_all_beer_df[\"TYPE OF BEER/ALE\"] = prod_all_beer_df[\"TYPE OF BEER/ALE\"].replace(\"MISSING\", \"BEER\")\n",
    "prod_all_beer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flavor_name</th>\n",
       "      <th>flavor_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO FLAVOR</td>\n",
       "      <td>NO FLAVOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASSORTED</td>\n",
       "      <td>ASSORTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RASPBERRY</td>\n",
       "      <td>RASPBERRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUM</td>\n",
       "      <td>RUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WATERMELON</td>\n",
       "      <td>WATERMELON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flavor_name  flavor_cat\n",
       "0   NO FLAVOR   NO FLAVOR\n",
       "1    ASSORTED    ASSORTED\n",
       "2   RASPBERRY   RASPBERRY\n",
       "3         RUM         RUM\n",
       "4  WATERMELON  WATERMELON"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique flavors\n",
    "\n",
    "flavor_df = prod_all_beer_df[[\"FLAVOR/SCENT\"]].dropna().drop_duplicates()\n",
    "flavor_df.rename(columns={\"FLAVOR/SCENT\": \"flavor_name\"}, inplace=True)\n",
    "flavor_df[\"flavor_cat\"] = flavor_df[\"flavor_name\"]\n",
    "flavor_df.reset_index(drop=True, inplace=True)\n",
    "flavor_df.to_csv(\"./OpenRefine_data/pre-openrefine/flavor.csv\", index=False)\n",
    "flavor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>packaging_name</th>\n",
       "      <th>packaging_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>BOX</td>\n",
       "      <td>BOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>PLASTIC JUG</td>\n",
       "      <td>PLASTIC JUG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>BOTTLE IN TOOLBOX</td>\n",
       "      <td>BOTTLE IN TOOLBOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>TALL CAN</td>\n",
       "      <td>TALL CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>PLASTIC SECURED CAN</td>\n",
       "      <td>PLASTIC SECURED CAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         packaging_name        packaging_cat\n",
       "73                  BOX                  BOX\n",
       "74          PLASTIC JUG          PLASTIC JUG\n",
       "75    BOTTLE IN TOOLBOX    BOTTLE IN TOOLBOX\n",
       "76             TALL CAN             TALL CAN\n",
       "77  PLASTIC SECURED CAN  PLASTIC SECURED CAN"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique packaging\n",
    "\n",
    "packaging_df = prod_all_beer_df[[\"PACKAGE\"]].dropna().drop_duplicates()\n",
    "packaging_df.rename(columns={\"PACKAGE\": \"packaging_name\"}, inplace=True)\n",
    "packaging_df[\"packaging_cat\"] = packaging_df[\"packaging_name\"]\n",
    "packaging_df.reset_index(drop=True, inplace=True)\n",
    "packaging_df.to_csv(\"./OpenRefine_data/pre-openrefine/packaging.csv\", index=False)\n",
    "packaging_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_type_name</th>\n",
       "      <th>beer_type_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>SCHWARZBIER</td>\n",
       "      <td>SCHWARZBIER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>BANANA</td>\n",
       "      <td>BANANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>WHITE</td>\n",
       "      <td>WHITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>WHEAT LAGER</td>\n",
       "      <td>WHEAT LAGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>HEFEDUNKEL</td>\n",
       "      <td>HEFEDUNKEL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_type_name beer_type_cat\n",
       "89    SCHWARZBIER   SCHWARZBIER\n",
       "90         BANANA        BANANA\n",
       "91          WHITE         WHITE\n",
       "92    WHEAT LAGER   WHEAT LAGER\n",
       "93     HEFEDUNKEL    HEFEDUNKEL"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique beer_type\n",
    "\n",
    "beer_type_df = prod_all_beer_df[[\"TYPE OF BEER/ALE\"]].dropna().drop_duplicates()\n",
    "beer_type_df.rename(columns={\"TYPE OF BEER/ALE\": \"beer_type_name\"}, inplace=True)\n",
    "beer_type_df[\"beer_type_cat\"] = beer_type_df[\"beer_type_name\"]\n",
    "beer_type_df.reset_index(drop=True, inplace=True)\n",
    "beer_type_df.to_csv(\"./OpenRefine_data/pre-openrefine/beer_type.csv\", index=False)\n",
    "beer_type_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Normalisation\n",
    "\n",
    "The clustered data on `beer-type`, `flavors`, and `packaging` are used to normalise the `UPC` product data. ID's of each unique category is added to each dataframe and dictionaries are created for future mapping to the `UPC` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "flavor_df = pd.read_csv(\"./OpenRefine_data/post-openrefine/flavor-or.csv\")\n",
    "flavor_df = flavor_df.assign(flavor_id = flavor_df[\"flavor_cat\"].astype('category').cat.codes).sort_values(by=['flavor_id'])\n",
    "flavor_df.reset_index(drop=True, inplace=True)\n",
    "flavor_dict = flavor_df.set_index(\"flavor_name\")[\"flavor_id\"].to_dict()\n",
    "\n",
    "packaging_df = pd.read_csv(\"./OpenRefine_data/post-openrefine/packaging-or.csv\")\n",
    "packaging_df = packaging_df.assign(packaging_id = packaging_df[\"packaging_cat\"].astype('category').cat.codes).sort_values(by=['packaging_id'])\n",
    "packaging_df.reset_index(drop=True, inplace=True)\n",
    "packaging_dict = packaging_df.set_index(\"packaging_name\")[\"packaging_id\"].to_dict()\n",
    "\n",
    "beer_type_df = pd.read_csv(\"./OpenRefine_data/post-openrefine/beer_type-or.csv\")\n",
    "beer_type_df = beer_type_df.assign(beer_type_id = beer_type_df[\"beer_type_cat\"].astype('category').cat.codes).sort_values(by=['beer_type_id'])\n",
    "beer_type_df.reset_index(drop=True, inplace=True)\n",
    "beer_type_dict = beer_type_df.set_index(\"beer_type_name\")[\"beer_type_id\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vendor (brand) is also assigned a unique ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique vendor\n",
    "\n",
    "vendor_df = prod_all_beer_df[[\"L4\"]].replace(\"MISSING\", np.nan).replace(\"ALL OTHERS\", np.nan).replace(\"PRIVATE LABEL\", np.nan).dropna().drop_duplicates()\n",
    "vendor_df.rename(columns={\"L4\": \"vendor_name\"}, inplace=True)\n",
    "vendor_df[\"vendor_id\"] = np.arange(1,1+len(vendor_df))\n",
    "vendor_df.reset_index(drop=True, inplace=True)\n",
    "vendor_dict = vendor_df.set_index(\"vendor_name\")[\"vendor_id\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe of unique products (defined by UPC codes) is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UPC</th>\n",
       "      <th>SY</th>\n",
       "      <th>GE</th>\n",
       "      <th>VEND</th>\n",
       "      <th>ITEM</th>\n",
       "      <th>domestic</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>VOL_EQ</th>\n",
       "      <th>beer_type_id</th>\n",
       "      <th>packaging_id</th>\n",
       "      <th>flavor_id</th>\n",
       "      <th>UPC_id</th>\n",
       "      <th>total_vol_oz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24308</th>\n",
       "      <td>00-01-82054-10990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82054</td>\n",
       "      <td>10990</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>106</td>\n",
       "      <td>24309</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24309</th>\n",
       "      <td>27-01-04200-03998</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>4200</td>\n",
       "      <td>3998</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>0.5868</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>106</td>\n",
       "      <td>24310</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24310</th>\n",
       "      <td>00-02-08205-41044</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8205</td>\n",
       "      <td>41044</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>24311</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24311</th>\n",
       "      <td>06-01-13395-00007</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13395</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>514</td>\n",
       "      <td>0.5868</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>106</td>\n",
       "      <td>24312</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24312</th>\n",
       "      <td>00-01-82153-33109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82153</td>\n",
       "      <td>33109</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>24313</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     UPC  SY  GE   VEND   ITEM  domestic  vendor_id  VOL_EQ  \\\n",
       "24308  00-01-82054-10990   0   1  82054  10990         0        512  0.0587   \n",
       "24309  27-01-04200-03998  27   1   4200   3998         0        512  0.5868   \n",
       "24310  00-02-08205-41044   0   2   8205  41044         0        512  0.2500   \n",
       "24311  06-01-13395-00007   6   1  13395      7         0        514  0.5868   \n",
       "24312  00-01-82153-33109   0   1  82153  33109         0        516  0.0441   \n",
       "\n",
       "       beer_type_id  packaging_id  flavor_id  UPC_id  total_vol_oz  \n",
       "24308            22            12        106   24309          11.0  \n",
       "24309            22            18        106   24310         113.0  \n",
       "24310            22            13        106   24311          48.0  \n",
       "24311             7            18        106   24312         113.0  \n",
       "24312             7            13        106   24313           8.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_all_beer_unique_df = prod_all_beer_df.drop_duplicates(subset=\"UPC\")\n",
    "\n",
    "prod_all_beer_unique_df = prod_all_beer_unique_df[prod_all_beer_unique_df.L4 != \"ALL OTHERS\"]\n",
    "prod_all_beer_unique_df = prod_all_beer_unique_df[prod_all_beer_unique_df.L4 != \"PRIVATE LABEL\"]\n",
    "prod_all_beer_unique_df[\"domestic\"] = [1 if x == \"DOMESTIC BEER/ALE (INC NON-ALCOH\" else 0 for x in prod_all_beer_unique_df[\"L2\"]]\n",
    "prod_all_beer_unique_df = prod_all_beer_unique_df[[\"UPC\", \"SY\", \"GE\", \"VEND\", \"ITEM\", \"domestic\", \"L4\", \"VOL_EQ\", \"TYPE OF BEER/ALE\", \"PACKAGE\", \"FLAVOR/SCENT\"]]\n",
    "prod_all_beer_unique_df.rename(columns={\"L4\": \"vendor_id\", \"TYPE OF BEER/ALE\": \"beer_type_id\", \"PACKAGE\": \"packaging_id\", \"FLAVOR/SCENT\": \"flavor_id\"}, inplace=True)\n",
    "\n",
    "prod_all_beer_unique_df[\"vendor_id\"] = prod_all_beer_unique_df[\"vendor_id\"].map(vendor_dict)\n",
    "prod_all_beer_unique_df[\"beer_type_id\"] = prod_all_beer_unique_df[\"beer_type_id\"].map(beer_type_dict)\n",
    "prod_all_beer_unique_df[\"beer_type_id\"] = prod_all_beer_unique_df[\"beer_type_id\"].astype('Int64')\n",
    "prod_all_beer_unique_df[\"packaging_id\"] = prod_all_beer_unique_df[\"packaging_id\"].map(packaging_dict)\n",
    "prod_all_beer_unique_df[\"packaging_id\"] = prod_all_beer_unique_df[\"packaging_id\"].astype('Int64')\n",
    "prod_all_beer_unique_df[\"flavor_id\"] = prod_all_beer_unique_df[\"flavor_id\"].map(flavor_dict)\n",
    "prod_all_beer_unique_df[\"flavor_id\"] = prod_all_beer_unique_df[\"flavor_id\"].astype('Int64')\n",
    "\n",
    "prod_all_beer_unique_df.reset_index(drop=True, inplace=True)\n",
    "prod_all_beer_unique_df[\"UPC_id\"] = np.arange(1,1+len(prod_all_beer_unique_df))\n",
    "prod_all_beer_unique_df.reset_index(drop=True, inplace=True)\n",
    "prod_all_beer_unique_df[\"total_vol_oz\"] = (prod_all_beer_unique_df[\"VOL_EQ\"]*192).round()\n",
    "prod_all_beer_unique_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPC codes in `sales` tables are atomized with no leading zeros.  \n",
    "Will need to normalise sales tables by replacing atomized UPC codes by surrogate UPC_id codes instead.  \n",
    "Can't use UPC column in `prod_all_beer_unique_df` to make dictionary since values have leading zeros.  \n",
    "Create df by concat-ing \"SY\", \"GE\", \"VEND\", \"ITEM\" columns with dash as separator.  \n",
    "Create dict for use in Section `4.3`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UPC_id</th>\n",
       "      <th>UPC_atom_concat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0-1-85674-60002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0-1-85674-60001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>27-1-15502-1124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0-1-80020-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0-1-80020-24221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UPC_id  UPC_atom_concat\n",
       "0       1  0-1-85674-60002\n",
       "1       2  0-1-85674-60001\n",
       "2       3  27-1-15502-1124\n",
       "3       4      0-1-80020-1\n",
       "4       5  0-1-80020-24221"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_upc_upcid_df = prod_all_beer_unique_df[[\"UPC_id\", \"SY\", \"GE\", \"VEND\", \"ITEM\"]]\n",
    "concat_upc_atom = atom_upc_upcid_df[[\"SY\", \"GE\", \"VEND\", \"ITEM\"]].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\n",
    "atom_upc_upcid_df = pd.concat([atom_upc_upcid_df, concat_upc_atom], axis=1)\n",
    "atom_upc_upcid_df.drop([\"SY\", \"GE\", \"VEND\", \"ITEM\"], axis = 1, inplace=True)\n",
    "atom_upc_upcid_df.rename(columns = {0: \"UPC_atom_concat\"}, inplace=True)\n",
    "atom_upc_upcid_dict = atom_upc_upcid_df.set_index(\"UPC_atom_concat\")[\"UPC_id\"].to_dict()\n",
    "\n",
    "atom_upc_upcid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Push to MySQL server\n",
    "\n",
    "Before doing so, keep only unique categories and ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flavor_df.drop([\"flavor_name\"],axis=1, inplace=True)\n",
    "flavor_df.drop_duplicates(inplace=True)\n",
    "flavor_df.to_sql('flavor', con = engine, if_exists = 'append', chunksize = 1000, index = False)\n",
    "\n",
    "packaging_df.drop([\"packaging_name\"],axis=1, inplace=True)\n",
    "packaging_df.drop_duplicates(inplace=True)\n",
    "packaging_df.to_sql('packaging', con = engine, if_exists = 'append', chunksize = 1000, index = False)\n",
    "\n",
    "beer_type_df.drop([\"beer_type_name\"],axis=1, inplace=True)\n",
    "beer_type_df.drop_duplicates(inplace=True)\n",
    "beer_type_df.to_sql('beer_type', con = engine, if_exists = 'append', chunksize = 1000, index = False)\n",
    "\n",
    "vendor_df.to_sql('vendor', con = engine, if_exists = 'append', chunksize = 1000, index = False)\n",
    "\n",
    "prod_all_beer_unique_df.to_sql('upc', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Store data\n",
    "\n",
    "### 6.1 Import the store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200032 GR 28.11499 NEW YORK                 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200059 GR 20.80499 PHILADELPHIA             1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200171 GR   25.282 MILWAUKEE                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200197 GR   16.616 PEORIA/SPRINGFLD.         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200272 GR 10.91199 LOS ANGELES               ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              string\n",
       "0   200032 GR 28.11499 NEW YORK                 1...\n",
       "1   200059 GR 20.80499 PHILADELPHIA             1...\n",
       "2   200171 GR   25.282 MILWAUKEE                 ...\n",
       "3   200197 GR   16.616 PEORIA/SPRINGFLD.         ...\n",
       "4   200272 GR 10.91199 LOS ANGELES               ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store (Delivery_Stores) tables\n",
    "\n",
    "stores_all_df = pd.concat([pd.read_csv(f, sep=\"\\t\") for f in glob.glob(\"./IRI BEER DATASET/Year*/Delivery_Stores\")], ignore_index = True, sort=False)\n",
    "stores_all_df.columns = [\"string\"]\n",
    "stores_all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The store data is vertically aligned but not tab-separated, so it is read into a dataframe as a string. Attributes are manually extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_id            int64\n",
       "outlet_cat_name    object\n",
       "market_name        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split column by character location\n",
    "\n",
    "stores_all_df[\"store_id\"] = stores_all_df.string.str[0:7].astype(str).astype(int)\n",
    "stores_all_df[\"outlet_cat_name\"] = stores_all_df.string.str[8:10]\n",
    "stores_all_df[\"market_name\"] = stores_all_df.string.str[20:45]\n",
    "stores_all_df[\"market_name\"] = stores_all_df[\"market_name\"].apply(lambda x: x.strip())\n",
    "\n",
    "outlet_cat_convert_dict = {\"DR\": \"drug\", \"GR\": \"groceries\", \"MA\": \"mass\", \"DK\": \"drug\", \"GK\": \"groceries\", \"MK\": \"mass\"}\n",
    "stores_all_df[\"outlet_cat_name\"] = stores_all_df[\"outlet_cat_name\"].map(outlet_cat_convert_dict)\n",
    "stores_all_df.drop([\"string\"], axis = 1, inplace=True)\n",
    "stores_all_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "stores_all_df.drop_duplicates(subset=\"store_id\", inplace=True)\n",
    "stores_all_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>outlet_cat_name</th>\n",
       "      <th>market_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200032</td>\n",
       "      <td>groceries</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200059</td>\n",
       "      <td>groceries</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200171</td>\n",
       "      <td>groceries</td>\n",
       "      <td>MILWAUKEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200197</td>\n",
       "      <td>groceries</td>\n",
       "      <td>PEORIA/SPRINGFLD.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200272</td>\n",
       "      <td>groceries</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id outlet_cat_name        market_name\n",
       "0    200032       groceries           NEW YORK\n",
       "1    200059       groceries       PHILADELPHIA\n",
       "2    200171       groceries          MILWAUKEE\n",
       "3    200197       groceries  PEORIA/SPRINGFLD.\n",
       "4    200272       groceries        LOS ANGELES"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores_all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Normalisation\n",
    "\n",
    "Dictionaries for outlet_category (grocery store, drug store) and market (Los Angeles, Chicago, New York, etc) are created to normalise the outlet categories and markets. The market names are manually amended in a `.csv` such that it is readable by Tableau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlet_cat_name</th>\n",
       "      <th>outlet_cat_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>groceries</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drug</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  outlet_cat_name  outlet_cat_id\n",
       "0       groceries              1\n",
       "1            drug              2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique outlet_cat\n",
    "\n",
    "outlet_cat_df = stores_all_df[[\"outlet_cat_name\"]].drop_duplicates()\n",
    "outlet_cat_df[\"outlet_cat_id\"] = np.arange(1,1+len(outlet_cat_df))\n",
    "outlet_cat_df.reset_index(drop=True, inplace=True)\n",
    "outlet_cat_dict = outlet_cat_df.set_index(\"outlet_cat_name\")[\"outlet_cat_id\"].to_dict()\n",
    "outlet_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_name</th>\n",
       "      <th>market_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MILWAUKEE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEORIA/SPRINGFLD.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         market_name  market_id\n",
       "0           NEW YORK          1\n",
       "1       PHILADELPHIA          2\n",
       "2          MILWAUKEE          3\n",
       "3  PEORIA/SPRINGFLD.          4\n",
       "4        LOS ANGELES          5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique market\n",
    "\n",
    "market_df = stores_all_df[[\"market_name\"]].drop_duplicates()\n",
    "market_df[\"market_id\"] = np.arange(1,1+len(market_df))\n",
    "market_df.reset_index(drop=True, inplace=True)\n",
    "market_df.to_csv(\"./OpenRefine_data/pre-openrefine/market.csv\", index=False)\n",
    "market_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_name</th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>market_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NEW YORK CITY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MILWAUKEE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>MILWAUKEE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEORIA/SPRINGFLD.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>PEORIA/SPRINGFLD.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         market_name region         state               city  market_id\n",
       "0           NEW YORK    NaN      NEW YORK      NEW YORK CITY          1\n",
       "1       PHILADELPHIA    NaN  PENNSYLVANIA       PHILADELPHIA          2\n",
       "2          MILWAUKEE    NaN     WISCONSIN          MILWAUKEE          3\n",
       "3  PEORIA/SPRINGFLD.    NaN      ILLINOIS  PEORIA/SPRINGFLD.          4\n",
       "4        LOS ANGELES    NaN    CALIFORNIA        LOS ANGELES          5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_df  = pd.read_csv(\"./OpenRefine_data/post-openrefine/market-or.csv\")\n",
    "market_dict = market_df.set_index(\"market_name\")[\"market_id\"].to_dict()\n",
    "\n",
    "market_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>outlet_cat_id</th>\n",
       "      <th>market_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3579</th>\n",
       "      <td>933196</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>8028829</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3581</th>\n",
       "      <td>238337</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>684577</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>1086089</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      store_id  outlet_cat_id  market_id\n",
       "3579    933196              1          2\n",
       "3580   8028829              2          3\n",
       "3581    238337              1         33\n",
       "3582    684577              1          2\n",
       "3583   1086089              1         40"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores_all_df[\"outlet_cat_name\"] = stores_all_df[\"outlet_cat_name\"].map(outlet_cat_dict)\n",
    "stores_all_df[\"market_name\"] = stores_all_df[\"market_name\"].map(market_dict)\n",
    "stores_all_df.rename(columns = {\"outlet_cat_name\": \"outlet_cat_id\", \"market_name\": \"market_id\"}, inplace=True)\n",
    "stores_all_df.reset_index(drop=True, inplace=True)\n",
    "stores_all_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Push to MySQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlet_cat_df.to_sql('outlet_cat', con = engine, if_exists = 'append', chunksize = 1000, index = False)\n",
    "market_df.to_sql('market', con = engine, if_exists = 'append', chunksize = 1000, index = False)\n",
    "stores_all_df.to_sql('store', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Week table\n",
    "\n",
    "Create a week table to convert IRI week codes to calendar date, refers to the Sunday of each week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_index = pd.date_range(start='12/30/2000', end='01/01/2013', freq='W-MON')\n",
    "week_df = week_index.to_frame(index=False)\n",
    "week_df.columns = [\"date\"]\n",
    "week_df[\"week_id\"] = np.arange(1114,1114+len(week_df))\n",
    "week_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>week_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-08</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-15</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-22</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-29</td>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  week_id\n",
       "0 2001-01-01     1114\n",
       "1 2001-01-08     1115\n",
       "2 2001-01-15     1116\n",
       "3 2001-01-22     1117\n",
       "4 2001-01-29     1118"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import into MySQL server\n",
    "\n",
    "week_df.to_sql('week', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Sales Data\n",
    "\n",
    "Sales data are stored in `YearXX` directories with the naming convention: `beer_<OUTLET_CAT>_<START_WEEKID>_<END_WEEK_ID>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 files and the total size of sales data is 6.93 GB.\n"
     ]
    }
   ],
   "source": [
    "# List of all sales data and total size\n",
    "\n",
    "sales_file_list = glob.glob(\"./IRI BEER DATASET/Year*/beer_????_????_????\")\n",
    "\n",
    "sales_files_size_GB = round(sum([os.stat(file).st_size for file in sales_file_list])/(1024**3),2)\n",
    "print(\"There are\", len(sales_file_list), \"files and the total size of sales data is\", sales_files_size_GB, \"GB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since files are big but each file has the same spacing format, for each sales file:\n",
    "1. `read_table()` into dataframe\n",
    "2. Split string into columns by character position (IRI_KEY, WEEK, SY, GE, VEND, ITEM, UNITS, DOLLARS)\n",
    "3. Push to mySQL by `if_exists = 'append'` method\n",
    "\n",
    "Estimated time for manipulating and importing sales data: 2.5 hours. System: macOS 10.15.1, Intel 7th gen Core i5 (I5-7267U), 8GB memory, Iris Plus Graphics 650."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./IRI BEER DATASET/Year9/beer_groc_1531_1582',\n",
       " './IRI BEER DATASET/Year9/beer_drug_1531_1582',\n",
       " './IRI BEER DATASET/Year7/beer_groc_1427_1478',\n",
       " './IRI BEER DATASET/Year7/beer_drug_1427_1478',\n",
       " './IRI BEER DATASET/Year1/beer_drug_1114_1165',\n",
       " './IRI BEER DATASET/Year1/beer_groc_1114_1165']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_file_list[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [2:22:32<00:00, 433.04s/it]\n"
     ]
    }
   ],
   "source": [
    "for series in tqdm(sales_file_list): \n",
    "    sales_each_df = pd.read_csv(series, sep=\"\\t\")\n",
    "    sales_each_df.columns = [\"string\"]\n",
    "    \n",
    "    # split non-separated data (string) into columns\n",
    "    sales_each_df[\"store_id\"] = sales_each_df.string.str[0:7].astype(str).astype(int)\n",
    "    sales_each_df[\"week_id\"] = sales_each_df.string.str[8:12].astype(str).astype(int)\n",
    "    sales_each_df[\"SY\"] = sales_each_df.string.str[13:15].astype(str).astype(int)\n",
    "    sales_each_df[\"GE\"] = sales_each_df.string.str[16:18].astype(str).astype(int)\n",
    "    sales_each_df[\"VEND\"] = sales_each_df.string.str[19:24].astype(str).astype(int)\n",
    "    sales_each_df[\"ITEM\"] = sales_each_df.string.str[25:30].astype(str).astype(int)\n",
    "    sales_each_df[\"UNITS\"] = sales_each_df.string.str[31:36].astype(str).astype(int)\n",
    "    sales_each_df[\"DOLLARS\"] = sales_each_df.string.str[37:45].astype(str).astype(float)\n",
    "    sales_each_df.drop([\"string\"], axis = 1, inplace=True)\n",
    "    sales_each_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    concat_upc_atom = sales_each_df[[\"SY\", \"GE\", \"VEND\", \"ITEM\"]].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\n",
    "    sales_each_df = pd.concat([sales_each_df, concat_upc_atom], axis=1)\n",
    "    sales_each_df.drop([\"SY\", \"GE\", \"VEND\", \"ITEM\"], axis = 1, inplace=True)\n",
    "    sales_each_df.rename(columns = {0: \"UPC_atom_concat\"}, inplace=True)\n",
    "    sales_each_df[\"upc_id\"] = sales_each_df[\"UPC_atom_concat\"].map(atom_upc_upcid_dict)\n",
    "    # sales_each_df[sales_each_df.isna().any(axis=1)]\n",
    "    # UPC code 0-1-11170-83511 does not exist in any of the `prod*_beer.xls*` tables so it's being dropped\n",
    "    sales_each_df.dropna(inplace = True)\n",
    "    sales_each_df.drop([\"UPC_atom_concat\"], axis = 1, inplace=True)\n",
    "    sales_each_df[\"upc_id\"] = sales_each_df[\"upc_id\"].astype('Int64')\n",
    "    \n",
    "    # dump into MySQL\n",
    "    #sales_each_df.to_sql('sales', con = engine, if_exists = 'append', chunksize = 1000, index = False)\n",
    "    sales_each_df.to_sql('sales', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Economic data\n",
    "\n",
    "FRED API documentation: [https://research.stlouisfed.org/docs/api/fred/ ]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 State abbreviations data\n",
    "\n",
    "**[IMPORTANT]** Downloaded from: http://www.whypad.com/wp-content/uploads/us_states.zip and placed in notebook directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_abbrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state state_abbrev\n",
       "0      Alaska           AK\n",
       "1     Arizona           AZ\n",
       "2    Arkansas           AR\n",
       "3  California           CA\n",
       "4    Colorado           CO"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_code_df = pd.read_csv(\"us_states.csv\")\n",
    "state_code_df.columns = [\"STATE\", \"state\", \"state_abbrev\"]\n",
    "state_code_df.drop([\"STATE\"], axis = 1, inplace=True)\n",
    "state_code_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. FRED economic data\n",
    "\n",
    "Economic series considered:  \n",
    "\n",
    "Real Gross Domestic Product: `GDPC1` â€»  \n",
    "US Unemployment Rate: `UNRATE` â€   \n",
    "State unemployment rate: `state_code` + `UR`; use state abbreviations dataframe from section `9.1` â€   \n",
    "CPI (for All Urban Consumers: All Items in U.S. City Average): `CPIAUCSL` â€   \n",
    "Long-Term Government Bond Yields: 10-year: Main (Including Benchmark): `IRLTLT01USM156N` â€   \n",
    "S&P/Case-Shiller U.S. National Home Price Index: `CSUSHPISA` â€   \n",
    "NBER based Recession Indicator: `USRECP` â€   \n",
    "Smoothed U.S. Recession Probabilities: `RECPROUSM156N` â€   \n",
    "University of Michigan: Consumer Sentiment: `UMCSENT` â€   \n",
    "University of Michigan: Inflation Expectation: `MICH` â€   \n",
    "OECD Indicator for the United States: `CSCICP03USM665S` â€   \n",
    "Brent Crude: `POILBREUSDM` â€   \n",
    "West Texas Intermediate: `DCOILWTICO` â€ â€ â€   \n",
    "Gold: `GOLDAMGBD228NLBM` â€ â€ â€    \n",
    "St. Louis Fed Financial Stress Index: `STLFSI` â€ â€   \n",
    "Effective Federal Funds Rate: `FEDFUNDS` â€   \n",
    "\n",
    "Note: quarterly â€», monthly â€ , weekly â€ â€ , daily â€ â€ â€ \n",
    "\n",
    "We form the list of economic series to pull from FRED:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_unemploy_api = [\"UNRATE\"]\n",
    "state_unemploy_api_list = state_code_df['state_abbrev'].astype(str) + \"UR\"\n",
    "state_unemploy_api_list = state_unemploy_api_list.tolist()\n",
    "all_unemploy_api = us_unemploy_api + state_unemploy_api_list\n",
    "\n",
    "other_api_list = [\"IRLTLT01USM156N\", \"CSUSHPISA\", \"GDPC1\", \"CPIAUCSL\", \"USRECP\", \"RECPROUSM156N\", \"UMCSENT\", \"MICH\", \"CSCICP03USM665S\", \"POILBREUSDM\", \"DCOILWTICO\", \"GOLDAMGBD228NLBM\", \"STLFSI\", \"FEDFUNDS\"]\n",
    "\n",
    "all_api = other_api_list + all_unemploy_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon setting up the API credentials, we pull data from FRED and nest it in DICTIONARY with format `{series_id : series_data_df}`. A dictionary is much preferred to dynamically creating objects through a loop since they are unnecessary, hard to create (use exec or globals()), and I can't use them dynamically anyway. But if you really want to, use `globals()`.\n",
    "\n",
    "Sometimes the API reaches 504 Gateway Timeout error and yells at you. Just keep trying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"<REDACTED KEY>\"\n",
    "fred = Fred(api_key=api_key)\n",
    "\n",
    "dict_series_values = {series: fred.get_series_latest_release(series).to_frame() for series in all_api}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean the dataframes and drop all observations that are not between 2001 and 2012:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRLTLT01USM156N</th>\n",
       "      <th>CSUSHPISA</th>\n",
       "      <th>GDPC1</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>USRECP</th>\n",
       "      <th>RECPROUSM156N</th>\n",
       "      <th>UMCSENT</th>\n",
       "      <th>MICH</th>\n",
       "      <th>CSCICP03USM665S</th>\n",
       "      <th>POILBREUSDM</th>\n",
       "      <th>...</th>\n",
       "      <th>SDUR</th>\n",
       "      <th>TNUR</th>\n",
       "      <th>TXUR</th>\n",
       "      <th>UTUR</th>\n",
       "      <th>VTUR</th>\n",
       "      <th>VAUR</th>\n",
       "      <th>WAUR</th>\n",
       "      <th>WVUR</th>\n",
       "      <th>WIUR</th>\n",
       "      <th>WYUR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-07</th>\n",
       "      <td>5.16</td>\n",
       "      <td>109.851</td>\n",
       "      <td>13222.69</td>\n",
       "      <td>175.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.04</td>\n",
       "      <td>94.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.966186</td>\n",
       "      <td>25.64</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-14</th>\n",
       "      <td>5.16</td>\n",
       "      <td>109.851</td>\n",
       "      <td>13222.69</td>\n",
       "      <td>175.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.04</td>\n",
       "      <td>94.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.966186</td>\n",
       "      <td>25.64</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-21</th>\n",
       "      <td>5.16</td>\n",
       "      <td>109.851</td>\n",
       "      <td>13222.69</td>\n",
       "      <td>175.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.04</td>\n",
       "      <td>94.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.966186</td>\n",
       "      <td>25.64</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-28</th>\n",
       "      <td>5.16</td>\n",
       "      <td>109.851</td>\n",
       "      <td>13222.69</td>\n",
       "      <td>175.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.04</td>\n",
       "      <td>94.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.966186</td>\n",
       "      <td>25.64</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-04</th>\n",
       "      <td>5.10</td>\n",
       "      <td>110.504</td>\n",
       "      <td>13222.69</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.44</td>\n",
       "      <td>90.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>100.593116</td>\n",
       "      <td>27.41</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-11</th>\n",
       "      <td>5.10</td>\n",
       "      <td>110.504</td>\n",
       "      <td>13222.69</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.44</td>\n",
       "      <td>90.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>100.593116</td>\n",
       "      <td>27.41</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-18</th>\n",
       "      <td>5.10</td>\n",
       "      <td>110.504</td>\n",
       "      <td>13222.69</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.44</td>\n",
       "      <td>90.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>100.593116</td>\n",
       "      <td>27.41</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-25</th>\n",
       "      <td>5.10</td>\n",
       "      <td>110.504</td>\n",
       "      <td>13222.69</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.44</td>\n",
       "      <td>90.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>100.593116</td>\n",
       "      <td>27.41</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-04</th>\n",
       "      <td>4.89</td>\n",
       "      <td>111.111</td>\n",
       "      <td>13222.69</td>\n",
       "      <td>176.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.54</td>\n",
       "      <td>91.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>100.432111</td>\n",
       "      <td>24.40</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-11</th>\n",
       "      <td>4.89</td>\n",
       "      <td>111.111</td>\n",
       "      <td>13222.69</td>\n",
       "      <td>176.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.54</td>\n",
       "      <td>91.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>100.432111</td>\n",
       "      <td>24.40</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            IRLTLT01USM156N  CSUSHPISA     GDPC1  CPIAUCSL  USRECP  \\\n",
       "date                                                                 \n",
       "2001-01-07             5.16    109.851  13222.69     175.6     0.0   \n",
       "2001-01-14             5.16    109.851  13222.69     175.6     0.0   \n",
       "2001-01-21             5.16    109.851  13222.69     175.6     0.0   \n",
       "2001-01-28             5.16    109.851  13222.69     175.6     0.0   \n",
       "2001-02-04             5.10    110.504  13222.69     176.0     0.0   \n",
       "2001-02-11             5.10    110.504  13222.69     176.0     0.0   \n",
       "2001-02-18             5.10    110.504  13222.69     176.0     0.0   \n",
       "2001-02-25             5.10    110.504  13222.69     176.0     0.0   \n",
       "2001-03-04             4.89    111.111  13222.69     176.1     1.0   \n",
       "2001-03-11             4.89    111.111  13222.69     176.1     1.0   \n",
       "\n",
       "            RECPROUSM156N  UMCSENT  MICH  CSCICP03USM665S  POILBREUSDM  ...  \\\n",
       "date                                                                    ...   \n",
       "2001-01-07          18.04     94.7   3.0       100.966186        25.64  ...   \n",
       "2001-01-14          18.04     94.7   3.0       100.966186        25.64  ...   \n",
       "2001-01-21          18.04     94.7   3.0       100.966186        25.64  ...   \n",
       "2001-01-28          18.04     94.7   3.0       100.966186        25.64  ...   \n",
       "2001-02-04          21.44     90.6   2.8       100.593116        27.41  ...   \n",
       "2001-02-11          21.44     90.6   2.8       100.593116        27.41  ...   \n",
       "2001-02-18          21.44     90.6   2.8       100.593116        27.41  ...   \n",
       "2001-02-25          21.44     90.6   2.8       100.593116        27.41  ...   \n",
       "2001-03-04          25.54     91.5   2.8       100.432111        24.40  ...   \n",
       "2001-03-11          25.54     91.5   2.8       100.432111        24.40  ...   \n",
       "\n",
       "            SDUR  TNUR  TXUR  UTUR  VTUR  VAUR  WAUR  WVUR  WIUR  WYUR  \n",
       "date                                                                    \n",
       "2001-01-07   2.7   3.9   4.1   3.8   3.0   2.3   5.6   5.3   3.9   3.8  \n",
       "2001-01-14   2.7   3.9   4.1   3.8   3.0   2.3   5.6   5.3   3.9   3.8  \n",
       "2001-01-21   2.7   3.9   4.1   3.8   3.0   2.3   5.6   5.3   3.9   3.8  \n",
       "2001-01-28   2.7   3.9   4.1   3.8   3.0   2.3   5.6   5.3   3.9   3.8  \n",
       "2001-02-04   2.8   3.9   4.2   3.9   3.0   2.4   5.7   5.2   4.0   3.8  \n",
       "2001-02-11   2.8   3.9   4.2   3.9   3.0   2.4   5.7   5.2   4.0   3.8  \n",
       "2001-02-18   2.8   3.9   4.2   3.9   3.0   2.4   5.7   5.2   4.0   3.8  \n",
       "2001-02-25   2.8   3.9   4.2   3.9   3.0   2.4   5.7   5.2   4.0   3.8  \n",
       "2001-03-04   2.9   4.0   4.3   4.0   3.1   2.6   5.8   5.1   4.2   3.8  \n",
       "2001-03-11   2.9   4.0   4.3   4.0   3.1   2.6   5.8   5.1   4.2   3.8  \n",
       "\n",
       "[10 rows x 64 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for series, df in dict_series_values.items():\n",
    "    df.columns = [series]\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df.rename(columns={\"index\": \"date\"}, inplace = True)\n",
    "    pd.to_datetime(df['date'], format = \"%Y-%m-%d\")\n",
    "    dict_series_values[series] = df.loc[(df['date'] >= \"2001-01-01\") & (df['date'] <= \"2012-12-31\")]\n",
    "\n",
    "# Merge all economic data in dataframe\n",
    "econ_df = pd.concat([df.set_index('date') for (series, df) in dict_series_values.items()], axis=1, join='outer').reset_index()\n",
    "\n",
    "# Resample with monthly average\n",
    "econ_df_monthly = econ_df.set_index('date').resample('W').mean().ffill()\n",
    "econ_df_monthly.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRLTLT01USM156N</th>\n",
       "      <th>CSUSHPISA</th>\n",
       "      <th>GDPC1</th>\n",
       "      <th>CPIAUCSL</th>\n",
       "      <th>USRECP</th>\n",
       "      <th>RECPROUSM156N</th>\n",
       "      <th>UMCSENT</th>\n",
       "      <th>MICH</th>\n",
       "      <th>CSCICP03USM665S</th>\n",
       "      <th>POILBREUSDM</th>\n",
       "      <th>...</th>\n",
       "      <th>TXUR</th>\n",
       "      <th>UTUR</th>\n",
       "      <th>VTUR</th>\n",
       "      <th>VAUR</th>\n",
       "      <th>WAUR</th>\n",
       "      <th>WVUR</th>\n",
       "      <th>WIUR</th>\n",
       "      <th>WYUR</th>\n",
       "      <th>date</th>\n",
       "      <th>econ_week_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>1.72</td>\n",
       "      <td>145.506</td>\n",
       "      <td>16239.138</td>\n",
       "      <td>231.221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>72.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>98.813582</td>\n",
       "      <td>109.64</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2012-12-09</td>\n",
       "      <td>1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>1.72</td>\n",
       "      <td>145.506</td>\n",
       "      <td>16239.138</td>\n",
       "      <td>231.221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>72.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>98.813582</td>\n",
       "      <td>109.64</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2012-12-16</td>\n",
       "      <td>1738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1.72</td>\n",
       "      <td>145.506</td>\n",
       "      <td>16239.138</td>\n",
       "      <td>231.221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>72.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>98.813582</td>\n",
       "      <td>109.64</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2012-12-23</td>\n",
       "      <td>1739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>1.72</td>\n",
       "      <td>145.506</td>\n",
       "      <td>16239.138</td>\n",
       "      <td>231.221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>72.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>98.813582</td>\n",
       "      <td>109.64</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>1.72</td>\n",
       "      <td>145.506</td>\n",
       "      <td>16239.138</td>\n",
       "      <td>231.221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>72.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>98.813582</td>\n",
       "      <td>109.64</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     IRLTLT01USM156N  CSUSHPISA      GDPC1  CPIAUCSL  USRECP  RECPROUSM156N  \\\n",
       "622             1.72    145.506  16239.138   231.221     0.0           0.08   \n",
       "623             1.72    145.506  16239.138   231.221     0.0           0.08   \n",
       "624             1.72    145.506  16239.138   231.221     0.0           0.08   \n",
       "625             1.72    145.506  16239.138   231.221     0.0           0.08   \n",
       "626             1.72    145.506  16239.138   231.221     0.0           0.08   \n",
       "\n",
       "     UMCSENT  MICH  CSCICP03USM665S  POILBREUSDM  ...  TXUR  UTUR  VTUR  VAUR  \\\n",
       "622     72.9   3.2        98.813582       109.64  ...   6.5   5.0   4.6   5.8   \n",
       "623     72.9   3.2        98.813582       109.64  ...   6.5   5.0   4.6   5.8   \n",
       "624     72.9   3.2        98.813582       109.64  ...   6.5   5.0   4.6   5.8   \n",
       "625     72.9   3.2        98.813582       109.64  ...   6.5   5.0   4.6   5.8   \n",
       "626     72.9   3.2        98.813582       109.64  ...   6.5   5.0   4.6   5.8   \n",
       "\n",
       "     WAUR  WVUR  WIUR  WYUR       date  econ_week_id  \n",
       "622   7.4   7.4   6.9   5.1 2012-12-09          1737  \n",
       "623   7.4   7.4   6.9   5.1 2012-12-16          1738  \n",
       "624   7.4   7.4   6.9   5.1 2012-12-23          1739  \n",
       "625   7.4   7.4   6.9   5.1 2012-12-30          1740  \n",
       "626   7.4   7.4   6.9   5.1 2013-01-06          1740  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "econ_df_monthly['date'] = econ_df_monthly.index\n",
    "econ_df_monthly.reset_index(level=0, drop=True, inplace=True)\n",
    "econ_df_monthly.head()\n",
    "\n",
    "# Merge IRI week number ID's with economic dataframe \n",
    "econ_df_monthly = pd.merge_asof(econ_df_monthly, week_df, direction='nearest')\n",
    "econ_df_monthly.rename(columns={\"week_id\": \"econ_week_id\"}, inplace = True)\n",
    "econ_df_monthly.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import into MySQL server\n",
    "\n",
    "econ_df_monthly.to_sql('econ', con = engine, if_exists = 'replace', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Integration with Google Cloud Platforms and Google Cloud SQL Server\n",
    "\n",
    "1. Create GCP project: `depa-final-project-beer-2019`. ID: `directed-smoke-258516`.\n",
    "\n",
    "2. Create GCP VM instance: `beer-vm`. Allows full acces to all Cloud APIs. apt-get installed `git`.\n",
    "\n",
    "3. Create bucket: `depa-bucket-of-white-claws`. With `uniform` access control to ensure uniform access to all objects in bucket using bucket-level permissions. \n",
    "\n",
    "4. Create MySQL Cloud instance: `depa-cloud-beer`. No IP's of personal machines added as \"Authorized network\". Options: vCPUs=4, Memory=15GB, SSD storage=10 GB flexible, MySQL==5.7. \n",
    "\n",
    "5. Create empty database in Cloud: `beer`.\n",
    "\n",
    "6. Create database dump file with `mysqldump`. The dump file should be 4.81 GB in size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysqldump: [Warning] Using a password on the command line interface can be insecure.\n"
     ]
    }
   ],
   "source": [
    "!mysqldump --databases beer -h 127.0.0.1 -uroot -p --hex-blob --skip-triggers --single-transaction --set-gtid-purged=OFF --default-character-set=utf8mb4 > beer_dump.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Import dump file into `beer-cloud-sql.beer`. The full process will take approximately **one hour**. There will be an \"unknown error\" in your Notifications center about 20 minutes into the import process, but the circle to the left of the name of the instance is still spinning. It is actually not an error but a warning, and it does not imply that the import has failed. The the warning message is `<Use unique_checks=0 which is non deterministic>`. View the log file here: [https://console.cloud.google.com/logs/]. \n",
    "\n",
    "Note: mysqldump was preferred over direct migration through MySQL Workbench due to internet speed limitation. The `beer` database has a size of 17 GB, whilst the dump file has a size of 3 GB. I am trading off the time required for migration and upload with the time required to reindex and rebuild the database on GCP. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 11. Dataviz\n",
    "\n",
    "This project uses Tableau as dataviz. Upon granting permissions by registering public IP addresses, personal machines would be able to connect to the Cloud SQL instance `cloud-sql-beer` through Tableau, Python, and MySQL. Currently the owner pays for the cost of data requests. In the future, this will admit a shared-cost model for each user/collaborator. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Google Cloud Computing (progressus ad infinitum)\n",
    "\n",
    "With the goal of expediting the data manipulation process, we turn to Google Cloud Platforms, on which we create a virtual machine with 4 vCPU cores and 15 GB memory. The raw IRI data, in addition to the data files after processed by OpenRefine/Excel, is hosted in a GCP Bucket. \n",
    "\n",
    "I wrote a shell script `gcp_vm_init.sh` which (i) installs the necessary Linux software, `pip`, and `Python3 packages`, (ii) pulls the respository from GitHub, with contains the OpenRefine files, Python scripts, and shell scripts, as well as (iii) downloads the raw IRI data from a GCP bucket where it is hosted. The script `gcp_finalProjectNotebook_2.py` takes the IRI dataset and the OpenRefine files as inputs, manipulates the data, and pushes it onto Google Cloud SQL server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 99. Convert this notebook into `.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook finalProjectNotebook.ipynb to script\n",
      "[NbConvertApp] Writing 32995 bytes to finalProjectNotebook.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script finalProjectNotebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
